# VL-SHAP
*Official Repo for the paper: ["Interpreting Vision and Language Generative Models with Semantic Visual Priors"](https://arxiv.org/abs/2304.14986).*

- **üóÉÔ∏è Repository:** [github.com/michelecafagna26/vl-shap](https://github.com/michelecafagna26/vl-shap)
- **üìú Paper:** [Interpreting Vision and Language Generative Models with Semantic Visual Priors](https://arxiv.org/abs/2304.14986)
- **üñäÔ∏è Contact:** michele.cafagna@um.edu.mt


### Requirements

```txt
python == 3.6.9
pytorch
torchvision
```

### Installation

```bash
pip install git+https://github.com/michelecafagna26/vl-shap.git#egg=semshap
```

### Overview
<img align="center" width="950" height="350" 
src="https://drive.google.com/uc?export=view&id=15kivtqVyD8DeL2ueL9qubOCKnEJXwWuA">

### Basic concepts

In order to generate a visual explanation for a caption generated by an image we need to:

1) extract visual features for the image 
2) run the explainer





### Citation Information

```BibTeX
@article{cafagna2023interpreting,
  title={Interpreting Vision and Language Generative Models with Semantic Visual Priors},
  author={Cafagna, Michele and Rojas-Barahona, Lina M and van Deemter, Kees and Gatt, Albert},
  journal={arXiv preprint arXiv:2304.14986},
  year={2023}
}
```
